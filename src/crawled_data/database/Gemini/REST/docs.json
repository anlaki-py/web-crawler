{
    "base_url": "https://ai.google.dev/gemini-api/docs/text-generation?lang=rest",
    "crawl_date": "2025-01-01T18:49:02.698339",
    "chunk_number": 1,
    "pages": [
        {
            "url": "https://ai.google.dev/gemini-api/docs/text-generation?lang=rest",
            "title": "Text generation  |  Gemini API  |  Google AI for Developers",
            "text_content": "Text generation  |  Gemini API  |  Google AI for Developers Models Solutions Build with Gemini Gemini API Google AI Studio Customize Gemma open models Gemma open models Multi-framework with Keras Fine-tune in Colab Run on-device Google AI Edge Gemini Nano on Android Chrome built-in web APIs Build responsibly Responsible GenAI Toolkit Secure AI Framework Code assistance Android Studio Chrome DevTools Colab Firebase Google Cloud JetBrains Jules Project IDX VS Code Showcase Gemini Showcase Gemini API Developer Competition Community Google AI Forum Gemini for Research / English Deutsch Español – América Latina Français Indonesia Italiano Polski Português – Brasil Shqip Tiếng Việt Türkçe Русский עברית العربيّة فارسی हिंदी বাংলা ภาษาไทย 中文 – 简体 中文 – 繁體 日本語 한국어 Sign in Gemini API docs API Reference SDKs Pricing Cookbook Models Gemini API docs API Reference SDKs Pricing Cookbook Solutions More Code assistance More Showcase More Community More Overview Get started Quickstart API keys Libraries Release notes Developer forum Models Gemini Gemini 2.0 Overview SDKs Thinking Mode Experimental models Capabilities Text generation Vision Audio understanding Long context Code execution Structured output Function calling Intro to function calling Function calling tutorial Extract structured data Document understanding Grounding Grounding with Google Search Use Google Search Suggestions Fine-tuning Intro to fine-tuning Fine-tuning tutorial Embeddings Guides Context caching Image generation Prompt engineering Intro to prompting Prompting strategies File prompting strategies Token counting OpenAI compatibility Billing info Safety Safety settings Safety guidance Additional resources Android (on-device) Firebase extensions Generative models Google AI Studio quickstart LearnLM Migrate to Cloud OAuth authentication Semantic retrieval System instructions Gemini for Research Gemini Academic Program Use cases Applications Code assistant Flutter code generator Content search Data exploration agent Writing assistant Slides reviewer Troubleshooting API troubleshooting AI Studio troubleshooting Google Workspace Request more quota Legal Terms of service Available regions Abuse monitoring Build with Gemini Gemini API Google AI Studio Customize Gemma open models Gemma open models Multi-framework with Keras Fine-tune in Colab Run on-device Google AI Edge Gemini Nano on Android Chrome built-in web APIs Build responsibly Responsible GenAI Toolkit Secure AI Framework Android Studio Chrome DevTools Colab Firebase Google Cloud JetBrains Jules Project IDX VS Code Gemini Showcase Gemini API Developer Competition Google AI Forum Gemini for Research Gemini 2.0 Flash Experimental is now available! Learn more Home Gemini API Models Send feedback Text generation Python Node.js Go REST The Gemini API can generate text output when provided text, images, video, and\naudio as input. This guide shows you how to generate text using the generateContent and streamGenerateContent methods. To learn about working with Gemini's vision and audio capabilities,\nrefer to the Vision and Audio guides. Generate text from text-only input The simplest way to generate text using the Gemini API is to provide the model\nwith a single text-only input, as shown in this example: curl \"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key= $GOOGLE_API_KEY \" \\ -H 'Content-Type: application/json' \\ -X POST \\ -d '{ \"contents\": [{ \"parts\":[{\"text\": \"Write a story about a magic backpack.\"}] }] }' 2 > /dev/null text_generation.sh In this case, the prompt (\"Explain how AI works\") doesn't\ninclude any output examples, system instructions, or formatting information.\nIt's a zero-shot approach. For some use cases, a one-shot or few-shot prompt\nmight produce output that's more aligned with user expectations. In some cases,\nyou might also want to provide system instructions to help the model\nunderstand the task or follow specific guidelines. Generate text from text-and-image input The Gemini API supports multimodal inputs that combine text with media files.\nThe following example shows how to generate text from text-and-image input: # Use a temporary file to hold the base64 encoded image data TEMP_B64 = $( mktemp ) trap 'rm -f \"$TEMP_B64\"' EXIT\nbase64 $B64FLAGS $IMG_PATH > \" $TEMP_B64 \" # Use a temporary file to hold the JSON payload TEMP_JSON = $( mktemp ) trap 'rm -f \"$TEMP_JSON\"' EXIT\n\ncat > \" $TEMP_JSON \" << EOF { \"contents\" : [{ \"parts\" : [ { \"text\" : \"Tell me about this instrument\" } , { \"inline_data\" : { \"mime_type\" : \"image/jpeg\" , \"data\" : \" $( cat \" $TEMP_B64 \" ) \" } } ] }] } EOF\n\ncurl \"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key= $GOOGLE_API_KEY \" \\ -H 'Content-Type: application/json' \\ -X POST \\ -d \"@ $TEMP_JSON \" 2 > /dev/null text_generation.sh As with text-only prompting, multimodal prompting can involve various approaches\nand refinements. Depending on the output from this example, you might want to\nadd steps to the prompt or be more specific in your instructions. To learn more,\nsee File prompting strategies . Generate a text stream By default, the model returns a response after completing the entire text\ngeneration process. You can achieve faster interactions by not waiting for the\nentire result, and instead use streaming to handle partial results. The following example shows how to implement streaming using the streamGenerateContent method to\ngenerate text from a text-only input prompt. curl \"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:streamGenerateContent?alt=sse&key= ${ GOOGLE_API_KEY } \" \\ -H 'Content-Type: application/json' \\ --no-buffer \\ -d '{ \"contents\":[{\"parts\":[{\"text\": \"Write a story about a magic backpack.\"}]}]}' text_generation.sh Build an interactive chat The Gemini SDK lets you collect multiple rounds of questions\nand responses, allowing users to step incrementally toward answers or get help\nwith multipart problems. This SDK feature provides an interface to keep\ntrack of conversations history, but behind the scenes uses the same generateContent method to create the response. The following code example shows a basic chat implementation: curl https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key = $GOOGLE_API_KEY \\ -H 'Content-Type: application/json' \\ -X POST \\ -d '{ \"contents\": [ {\"role\":\"user\", \"parts\":[{ \"text\": \"Hello\"}]}, {\"role\": \"model\", \"parts\":[{ \"text\": \"Great to meet you. What would you like to know?\"}]}, {\"role\":\"user\", \"parts\":[{ \"text\": \"I have two dogs in my house. How many paws are in my house?\"}]}, ] }' 2 > /dev/null | grep \"text\" chat.sh Enable chat streaming You can also use streaming with chat, as shown in the following example: curl https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:streamGenerateContent?alt = sse&key = $GOOGLE_API_KEY \\ -H 'Content-Type: application/json' \\ -X POST \\ -d '{ \"contents\": [ {\"role\":\"user\", \"parts\":[{ \"text\": \"Hello\"}]}, {\"role\": \"model\", \"parts\":[{ \"text\": \"Great to meet you. What would you like to know?\"}]}, {\"role\":\"user\", \"parts\":[{ \"text\": \"I have two dogs in my house. How many paws are in my house?\"}]}, ] }' 2 > /dev/null | grep \"text\" chat.sh Configure text generation Every prompt you send to the model includes\nparameters that control how the model generates responses. You can use GenerationConfig to\nconfigure these parameters. If you don't configure the parameters, the model\nuses default options, which can vary by model. The following example shows how to configure several of the available options. curl https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key = $GOOGLE_API_KEY \\ -H 'Content-Type: application/json' \\ -X POST \\ -d '{ \"contents\": [{ \"parts\":[ {\"text\": \"Write a story about a magic backpack.\"} ] }], \"safetySettings\": [ { \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_ONLY_HIGH\" } ], \"generationConfig\": { \"stopSequences\": [ \"Title\" ], \"temperature\": 1.0, \"maxOutputTokens\": 800, \"topP\": 0.8, \"topK\": 10 } }' 2 > /dev/null | grep \"text\" configure_model_parameters.sh stopSequences specifies the set of character sequences (up to 5) that will\nstop output generation. If specified, the API will stop at the first appearance\nof a stop_sequence . The stop sequence won't be included as part of the\nresponse. temperature controls the randomness of the output. Use higher values for more\ncreative responses, and lower values for more deterministic responses. Values\ncan range from [0.0, 2.0]. maxOutputTokens sets the maximum number of tokens to include in a candidate. topP changes how the model selects tokens for output. Tokens are selected from\nthe most to least probable until the sum of their probabilities equals the topP value. The default topP value is 0.95. topK changes how the model selects tokens for output. A topK of 1 means the\nselected token is the most probable among all the tokens in the model's\nvocabulary, while a topK of 3 means that the next token is selected from among\nthe 3 most probable using the temperature. Tokens are\nfurther filtered based on topP with the final token selected using temperature\nsampling. What's next Now that you have explored the basics of the Gemini API, you might want to\ntry: Vision understanding : Learn how to use\nGemini's native vision understanding to process images and videos. Audio understanding : Learn how to use\nGemini's native audio understanding to process audio files. Send feedback Except as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License , and code samples are licensed under the Apache 2.0 License . For details, see the Google Developers Site Policies . Java is a registered trademark of Oracle and/or its affiliates. Last updated 2024-12-28 UTC. Terms Privacy Manage cookies English Deutsch Español – América Latina Français Indonesia Italiano Polski Português – Brasil Shqip Tiếng Việt Türkçe Русский עברית العربيّة فارسی हिंदी বাংলা ภาษาไทย 中文 – 简体 中文 – 繁體 日本語 한국어",
            "meta_description": "Get started building chat and text generation apps with the Gemini API",
            "links": [
                "https://ai.google.dev/gemini-api/docs/text-generation"
            ],
            "timestamp": "2025-01-01T18:49:01.928679",
            "status_code": 200
        },
        {
            "url": "https://ai.google.dev/gemini-api/docs/text-generation",
            "title": "Text generation  |  Gemini API  |  Google AI for Developers",
            "text_content": "Text generation  |  Gemini API  |  Google AI for Developers Models Solutions Build with Gemini Gemini API Google AI Studio Customize Gemma open models Gemma open models Multi-framework with Keras Fine-tune in Colab Run on-device Google AI Edge Gemini Nano on Android Chrome built-in web APIs Build responsibly Responsible GenAI Toolkit Secure AI Framework Code assistance Android Studio Chrome DevTools Colab Firebase Google Cloud JetBrains Jules Project IDX VS Code Showcase Gemini Showcase Gemini API Developer Competition Community Google AI Forum Gemini for Research / English Deutsch Español – América Latina Français Indonesia Italiano Polski Português – Brasil Shqip Tiếng Việt Türkçe Русский עברית العربيّة فارسی हिंदी বাংলা ภาษาไทย 中文 – 简体 中文 – 繁體 日本語 한국어 Sign in Gemini API docs API Reference SDKs Pricing Cookbook Models Gemini API docs API Reference SDKs Pricing Cookbook Solutions More Code assistance More Showcase More Community More Overview Get started Quickstart API keys Libraries Release notes Developer forum Models Gemini Gemini 2.0 Overview SDKs Thinking Mode Experimental models Capabilities Text generation Vision Audio understanding Long context Code execution Structured output Function calling Intro to function calling Function calling tutorial Extract structured data Document understanding Grounding Grounding with Google Search Use Google Search Suggestions Fine-tuning Intro to fine-tuning Fine-tuning tutorial Embeddings Guides Context caching Image generation Prompt engineering Intro to prompting Prompting strategies File prompting strategies Token counting OpenAI compatibility Billing info Safety Safety settings Safety guidance Additional resources Android (on-device) Firebase extensions Generative models Google AI Studio quickstart LearnLM Migrate to Cloud OAuth authentication Semantic retrieval System instructions Gemini for Research Gemini Academic Program Use cases Applications Code assistant Flutter code generator Content search Data exploration agent Writing assistant Slides reviewer Troubleshooting API troubleshooting AI Studio troubleshooting Google Workspace Request more quota Legal Terms of service Available regions Abuse monitoring Build with Gemini Gemini API Google AI Studio Customize Gemma open models Gemma open models Multi-framework with Keras Fine-tune in Colab Run on-device Google AI Edge Gemini Nano on Android Chrome built-in web APIs Build responsibly Responsible GenAI Toolkit Secure AI Framework Android Studio Chrome DevTools Colab Firebase Google Cloud JetBrains Jules Project IDX VS Code Gemini Showcase Gemini API Developer Competition Google AI Forum Gemini for Research Gemini 2.0 Flash Experimental is now available! Learn more Home Gemini API Models Send feedback Text generation Python Node.js Go REST The Gemini API can generate text output when provided text, images, video, and\naudio as input. This guide shows you how to generate text using the generateContent and streamGenerateContent methods. To learn about working with Gemini's vision and audio capabilities,\nrefer to the Vision and Audio guides. What's next Now that you have explored the basics of the Gemini API, you might want to\ntry: Vision understanding : Learn how to use\nGemini's native vision understanding to process images and videos. Audio understanding : Learn how to use\nGemini's native audio understanding to process audio files. Send feedback Except as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License , and code samples are licensed under the Apache 2.0 License . For details, see the Google Developers Site Policies . Java is a registered trademark of Oracle and/or its affiliates. Last updated 2024-12-28 UTC. Terms Privacy Manage cookies English Deutsch Español – América Latina Français Indonesia Italiano Polski Português – Brasil Shqip Tiếng Việt Türkçe Русский עברית العربيّة فارسی हिंदी বাংলা ภาษาไทย 中文 – 简体 中文 – 繁體 日本語 한국어",
            "meta_description": "Get started building chat and text generation apps with the Gemini API",
            "links": [
                "https://ai.google.dev/gemini-api/docs/text-generation",
                "https://ai.google.dev/gemini-api/docs/text-generation",
                "https://ai.google.dev/gemini-api/docs/text-generation",
                "https://ai.google.dev/gemini-api/docs/text-generation",
                "https://ai.google.dev/gemini-api/docs/text-generation",
                "https://ai.google.dev/gemini-api/docs/text-generation"
            ],
            "timestamp": "2025-01-01T18:49:02.670234",
            "status_code": 200
        }
    ]
}